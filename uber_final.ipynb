{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e78ea1-8117-4247-a1df-144323574d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"chennai_final_dataset.csv\")\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df['event'] = df['event'].fillna('None')\n",
    "df['type'] = df['type'].fillna('None')\n",
    "df['traffic_impact'] = df['traffic_impact'].fillna('Low')\n",
    "\n",
    "\n",
    "\n",
    "daily_df = df.groupby(['date', 'Junction'], observed=False).agg({\n",
    "    'Vehicles': 'sum',\n",
    "    'temperature': 'mean',\n",
    "    'rain (mm)': 'sum',\n",
    "    'precipitation (mm)': 'sum',\n",
    "    'snow_depth (m)': 'sum',\n",
    "    'event': 'first',\n",
    "    'type': 'first',\n",
    "    'traffic_impact': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "daily_df['day_of_week'] = daily_df['date'].dt.dayofweek\n",
    "daily_df['month'] = daily_df['date'].dt.month\n",
    "daily_df['week_of_year'] = daily_df['date'].dt.isocalendar().week\n",
    "daily_df['is_weekend'] = (daily_df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "\n",
    "daily_df['is_event_day'] = (daily_df['event'] != 'None').astype(int)\n",
    "\n",
    "\n",
    "daily_df = daily_df.sort_values(['Junction', 'date'])\n",
    "\n",
    "daily_df['vehicles_lag_1'] = daily_df.groupby('Junction', observed=False)['Vehicles'].shift(1)\n",
    "daily_df['vehicles_lag_7'] = daily_df.groupby('Junction', observed=False)['Vehicles'].shift(7)\n",
    "\n",
    "\n",
    "daily_df['vehicles_roll_3'] = (\n",
    "    daily_df.groupby('Junction', observed=False)['Vehicles']\n",
    "            .rolling(3).mean().reset_index(0, drop=True)\n",
    ")\n",
    "\n",
    "daily_df['vehicles_roll_7'] = (\n",
    "    daily_df.groupby('Junction', observed=False)['Vehicles']\n",
    "            .rolling(7).mean().reset_index(0, drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "encoded_df = pd.get_dummies(\n",
    "    daily_df,\n",
    "    columns=['event', 'type', 'traffic_impact'],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "\n",
    "preprocessed_df = encoded_df.copy()\n",
    "\n",
    "preprocessed_df.head()\n",
    "\n",
    "\n",
    "explain this code \n",
    "\n",
    "df['traffic_zscore'] = (df['Vehicles'] - df['Vehicles'].mean()) / df['Vehicles'].std()\n",
    "df['rolling_7'] = df.groupby('Junction')['Vehicles'].rolling(7).mean().reset_index(0, drop=True)\n",
    "df['rolling_3'] = df.groupby('Junction')['Vehicles'].rolling(3).mean().reset_index(0, drop=True)\n",
    "\n",
    "threshold = df['Vehicles'].quantile(0.90)\n",
    "df['is_peak_day'] = (df['Vehicles'] >= threshold).astype(int)\n",
    "\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "weekday_pattern = df.groupby(['day_of_week', 'Junction'])['Vehicles'].mean()\n",
    "df['month'] = df['date'].dt.month\n",
    "monthly_pattern = df.groupby(['month', 'Junction'])['Vehicles'].mean()\n",
    "\n",
    "df[['Vehicles', 'temperature', 'rain (mm)']].corr()\n",
    "event_impact = df.groupby('event')['Vehicles'].mean().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "data = preprocessed_df.sort_values('date')\n",
    "\n",
    "X = data.drop(['Vehicles', 'date'], axis=1)\n",
    "y = data['Vehicles']\n",
    "\n",
    "\n",
    "\n",
    "X_clean = X.dropna()\n",
    "y_clean = y.loc[X_clean.index]\n",
    "\n",
    "\n",
    "split_idx = int(len(X_clean) * 0.8)\n",
    "\n",
    "X_train = X_clean.iloc[:split_idx]\n",
    "y_train = y_clean.iloc[:split_idx]\n",
    "\n",
    "X_val = X_clean.iloc[split_idx:]\n",
    "y_val = y_clean.iloc[split_idx:]\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    gb,\n",
    "    param_grid=param_grid_gb,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=tscv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_grid.fit(X_clean, y_clean)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "\n",
    "def evaluate(model, X_train, y_train, X_val, y_val):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    results = {\n",
    "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'Val MAE': mean_absolute_error(y_val, y_val_pred),\n",
    "        'Train RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'Val RMSE': np.sqrt(mean_squared_error(y_val, y_val_pred)),\n",
    "        'Train R2': r2_score(y_train, y_train_pred),\n",
    "        'Val R2': r2_score(y_val, y_val_pred)\n",
    "    }\n",
    "    return results, y_val_pred\n",
    "\n",
    "\n",
    "rf_results, rf_pred = evaluate(rf, X_train, y_train, X_val, y_val)\n",
    "gb_results, gb_pred = evaluate(best_gb, X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\" Random Forest Results:\\n\", rf_results)\n",
    "print(\"\\n Best Gradient Boosting Results:\\n\", gb_results)\n",
    "print(\"\\n Best GB Model:\", best_gb)\n",
    "\n",
    "\n",
    "cv_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_clean)):\n",
    "    X_tr, X_vl = X_clean.iloc[train_idx], X_clean.iloc[val_idx]\n",
    "    y_tr, y_vl = y_clean.iloc[train_idx], y_clean.iloc[val_idx]\n",
    "\n",
    "    model = GradientBoostingRegressor(random_state=42)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_vl)\n",
    "\n",
    "    cv_scores.append({\n",
    "        'Fold': fold + 1,\n",
    "        'MAE': mean_absolute_error(y_vl, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_vl, y_pred)),\n",
    "        'R2': r2_score(y_vl, y_pred)\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_scores)\n",
    "print(\"\\n Time-Based Cross-Validation Results:\\n\", cv_df)\n",
    "print(\"\\n Average CV Performance:\\n\", cv_df.mean())\n",
    "\n",
    "\n",
    "val_dates = data['date'].loc[X_val.index]\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(val_dates, y_val.values, label='Actual', linewidth=2)\n",
    "plt.plot(val_dates, gb_pred, label='Predicted (GB)', alpha=0.8)\n",
    "plt.title(\"Actual vs Predicted Traffic (Gradient Boosting)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Vehicles\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "residuals = y_val - gb_pred\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Residual Distribution (GB)\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(gb_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title(\"Residuals vs Predicted (GB)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
